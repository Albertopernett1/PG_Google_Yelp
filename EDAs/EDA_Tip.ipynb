{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YELP (tip.parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciamos nuestro proyecto desarrollando un Análisis y Depuración de Datos.\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-0RCR776:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>appName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f00bfc9350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la biblioteca para Koalas\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "collections.Callable = collections.abc.Callable\n",
    "\n",
    "import databricks.koalas as ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"YelpEDA\").getOrCreate()\n",
    "\n",
    "#Cargando el archivo con Tip.parquet usando Spark\n",
    "tip_spark_df = spark.read.parquet(r\"C:\\Users\\Pierinna\\Desktop\\DataSets_GoogleMaps\\PG_Google_Yelp\\Proyecto_Final\\Yelp_\\tip.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir Spark DataFrame a Koalas DataFrame:\n",
    "tip_koalas_df = ks.DataFrame(tip_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id             business_id                                                       text                 date  compliment_count\n",
      "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ                             Avengers time with the ladies.  2012-05-18 02:17:21                 0\n",
      "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg  They have lots of good deserts and tasty cuban sandwiches  2013-02-05 18:35:10                 0\n",
      "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg                     It's open even when you think it isn't  2013-08-18 00:56:08                 0\n",
      "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw                                  Very decent fried chicken  2017-06-27 23:05:38                 0\n",
      "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww                     Appetizers.. platter special for lunch  2012-10-06 19:43:09                 0\n"
     ]
    }
   ],
   "source": [
    "#Muestra las primeras filas del DataFrame:\n",
    "print(tip_koalas_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tip_koalas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de filas: 908915\n",
      "Numero de columnas: 5\n"
     ]
    }
   ],
   "source": [
    "#muestra la cantidad de filas y columnas\n",
    "print(\"Numero de filas:\", len(tip_koalas_df))\n",
    "print(\"Numero de columnas:\", len(tip_koalas_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos:\n",
      "user_id             object\n",
      "business_id         object\n",
      "text                object\n",
      "date                object\n",
      "compliment_count     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#vemos los tipos de datos de las columnas:\n",
    "print(\"Tipos de datos:\")\n",
    "print(tip_koalas_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id             0\n",
      "business_id         0\n",
      "text                0\n",
      "date                0\n",
      "compliment_count    0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#podemos ver la cantidad de valores nullos por columna:\n",
    "print(\"Valores nulos por columna\")\n",
    "print(tip_koalas_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATOS ANALITICOS PARA SPARK:\n",
    "\n",
    "- Dado que la cantidad de datos que tenemos son aproximadamente 1 Millon de estos, procedemos a utilizar Spark y Koalas como medio para observar de manera detallada los datos y poder pasar a un analisis general de cada uno de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|summary|             user_id|         business_id|                text|               date|    compliment_count|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|  count|              908915|              908915|              908915|             908915|              908915|\n",
      "|   mean|                null|                null|1.792114762548089...|               null|0.012524823553357574|\n",
      "| stddev|                null|                null|1.411112521356809...|               null| 0.12076339327984201|\n",
      "|    min|---r61b7EpVPkb4UV...|---kPU91CF4Lq2-Wl...|                   !|2009-04-16 13:11:49|                   0|\n",
      "|    max|zzxZW6U5lCCQQeVfL...|zzyx5x0Z7xXWWvWnZ...|to the apple gor...|2022-01-19 20:38:55|                   6|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos las estadisticas descriptivas:\n",
    "tip_spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Planteamos que las columnas Business_id y user_id sean unicos y no contengan datos incosistentes.\n",
    "- Se planteo analizar el texto de las reseñas, podría ser útil aplicar técnicas de procesamiento de lenguaje natural (NLP) para tokenizar, limpiar y analizar el contenido de las reseñas.\n",
    "- Se planteo analizar las fechas, podrías extraer información adicional como el día de la semana o el mes para obtener patrones estacionales.\n",
    "- Se planteo analizar y manejar los valores atípicos en la columna compliment_count utilizando los pasos que mencioné anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de user_ids únicos: 301758\n",
      "Total de business_ids únicos: 106193\n",
      "Valores atípicos en 'compliment_count':\n",
      "+----------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|user_id               |business_id           |text                                                                                                                                                                                                                                                                                                 |compliment_count|\n",
      "+----------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|tA1U-XSh9woo73eQmWGyAQ|xHwvbm1SJwtaZtOZzFQcmQ|If you haven't  been here in a good while or if you are used to the same place on the west coast called, Carl Jr. (both are applicable to me), please don't  come here for the turkey burger.  It is no longer on the menu.                                                                          |1               |\n",
      "|nhXyjGOCfi-EW09bJqfAzQ|1Efad30BdOeqqjX2d6P4sw|You MUST have the popover breakfast!!                                                                                                                                                                                                                                                                |1               |\n",
      "|RNupfU2QClRq_lRR3mEgrQ|5kWhgFvaf9_zeyOfO-2NxQ|Try the calamari, the chicken Marsala was great, and the ossobuco special was delicious. Great place, highly recommended!                                                                                                                                                                            |1               |\n",
      "|hCBKnwAKN0hcu6OTzuCAEw|plUxQaoTDXe7BPam9rNRgA|special right now for vday, buy 4 get 2 free!!!                                                                                                                                                                                                                                                      |1               |\n",
      "|alUlVVMx9NtfrvK4xAQy2w|C7WUvmGAz_t4FE_ycOPGUA|Try the in house eye of round at the deli. Sliced on the thicker side it makes a killer cold steak sandwich.                                                                                                                                                                                         |1               |\n",
      "|tslp3KJf3tATFHJnFzeyVA|UakVMT3xrpbFB2pHdxPjnw|This is the undisputed breakfast champion on Dunedin. How is it that gay restaurants are so good.                                                                                                                                                                                                    |1               |\n",
      "|bYENop4BuQepBjM1-BI3fA|79nXYNRPoZBc9_y_OLZg2w|Purse Hooks Under the Bar                                                                                                                                                                                                                                                                            |1               |\n",
      "|WcQ01IBbW0ID01EE7bdH4g|HRVv9HPqyLz1NhDIRsOAbg|My friend went there the other day.  Wasn't aware of any pitfalls.  They told him they couldn't process a title transfer because his driver's license had expired.  The purpose is for I.d., yet that \"practicing attorney\" steps in and decides to be the enforcer for the DMV.                     |1               |\n",
      "|3YhG4h4Ok654iVfqdmkuRg|xO6FIZL2UbhTuvUl9jI68A|They don't carry 1L bottles at this location - max 750mL                                                                                                                                                                                                                                             |1               |\n",
      "|bZIPI0QD1VEq0ejbWUm2ZA|cWu31txqrvLHMCUNdmnxfQ|I am a black lady. I ordered a White Lady. It was delicious.                                                                                                                                                                                                                                         |1               |\n",
      "|6hsAnihiLN7dvjXSjgDudA|QdncKkre1lMPUWszxi70rQ|Good selection on the buffet                                                                                                                                                                                                                                                                         |1               |\n",
      "|Xw7ZjaGfr0WNVt6s_5KZfA|_WrL7teoT0im_28inoePwg|$5 minimum purchase for WiFi access. Meanwhile a large iced coffee $3.50.                                                                                                                                                                                                                            |1               |\n",
      "|JWeXuv2B9lRhiXBcIzsi2Q|gCm3En8LqvXPcfiw9Tyh-g|Yelp says this business is closed but they are not .....                                                                                                                                                                                                                                             |1               |\n",
      "|5u1aDbRVb_BVlzxMEO-LWw|OMT709IPPEwN91CAXpe9dw|Try the j dawg!                                                                                                                                                                                                                                                                                      |1               |\n",
      "|-_Y8Mal7S750TsB6yMMDHA|zlNtAPz4GvSUiljQ-D3cvQ|The bbq wings are the best!                                                                                                                                                                                                                                                                          |1               |\n",
      "|r_82uuMMOAXhLnGnhbNddw|6d25hRt6Hz4SPc9Ih327gw|Yummmmmmy pizza.                                                                                                                                                                                                                                                                                     |1               |\n",
      "|M8kqIA2VGOsQAR8ukwhFlw|PGd06nrseC2YAIqP6S9gUA|They don't split check!! Just one credit card for 9ppl?? What?? Who does that??                                                                                                                                                                                                                      |1               |\n",
      "|P3odzsW6sIdba9Lmi91Ouw|-i0FqsGq2B-3FR-p68JfDw|The shrimp and grits are the bomb.                                                                                                                                                                                                                                                                   |1               |\n",
      "|F7HPo-1dtqiQatjmpa-YHQ|c5m3fkLzQZjGoHSERlXW6A|We experienced the same type of service from the white security guards at delilahs their all racist!                                                                                                                                                                                                 |1               |\n",
      "|bXOPSX-axrWVQduprZgSdw|qYGM6V73aSxc_1Pr_W28NQ|Everything is right with the ambience of this lovely place. I will caution you to hurry and get there,however, as the very accomplished chef who who owns and has run this gem for years is preparing to close it and move on to other things.  This is a class act preparing for a graceful closing.|1               |\n",
      "+----------------------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"YelpAnalysis\").getOrCreate()\n",
    "\n",
    "#Cargar los datos en el DataFrame\n",
    "tip_spark_df = spark.read.parquet(r\"C:\\Users\\Pierinna\\Desktop\\DataSets_GoogleMaps\\PG_Google_Yelp\\Proyecto_Final\\Yelp_\\tip.parquet\")\n",
    "\n",
    "#Verificar columnas de IDs\n",
    "user_id_counts = tip_spark_df.select(\"user_id\").distinct().count()\n",
    "business_id_counts = tip_spark_df.select(\"business_id\").distinct().count()\n",
    "print(f\"Total de user_ids únicos: {user_id_counts}\")\n",
    "print(f\"Total de business_ids únicos: {business_id_counts}\")\n",
    "\n",
    "#Procesamiento de texto (NLP)\n",
    "#Aquí se pueden aplicar técnicas de procesamiento de lenguaje natural al contenido de las reseñas en la columna 'text':\n",
    "\n",
    "#Procesamiento de fechas\n",
    "tip_spark_df = tip_spark_df.withColumn(\"date\", col(\"date\").cast(\"timestamp\"))\n",
    "tip_spark_df = tip_spark_df.withColumn(\"day_of_week\", F.dayofweek(\"date\"))\n",
    "tip_spark_df = tip_spark_df.withColumn(\"month\", F.month(\"date\"))\n",
    "\n",
    "#Valores atípicos en 'compliment_count'\n",
    "Q1 = tip_spark_df.approxQuantile(\"compliment_count\", [0.25], 0.05)[0]\n",
    "Q3 = tip_spark_df.approxQuantile(\"compliment_count\", [0.75], 0.05)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = tip_spark_df.filter((col(\"compliment_count\") < lower_bound) | (col(\"compliment_count\") > upper_bound))\n",
    "print(\"Valores atípicos en 'compliment_count':\")\n",
    "outliers.select(\"user_id\", \"business_id\", \"text\", \"compliment_count\").show(truncate=False)\n",
    "\n",
    "#Cerrar la sesión de Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/C:/Users/Pierinna/Desktop/DataSets_GoogleMaps/Archivos/ResultadoTIP.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m ruta_exportacion \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/Pierinna/Desktop/DataSets_GoogleMaps/Archivos/ResultadoTIP.parquet\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Guardar el DataFrame en formato Parquet con una sola partición\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tip_spark_df\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mparquet(ruta_exportacion, compression\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msnappy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(compression\u001b[39m=\u001b[39mcompression)\n\u001b[1;32m-> 1656\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mparquet(path)\n",
      "File \u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\Spark\\python\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/C:/Users/Pierinna/Desktop/DataSets_GoogleMaps/Archivos/ResultadoTIP.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "tip_spark_df = tip_spark_df.coalesce(1)\n",
    "\n",
    "# Ruta para guardar el archivo Parquet\n",
    "ruta_exportacion = 'C:/Users/Pierinna/Desktop/DataSets_GoogleMaps/Archivos/ResultadoTIP.parquet'\n",
    "\n",
    "# Guardar el DataFrame en formato Parquet con una sola partición\n",
    "tip_spark_df.write.parquet(ruta_exportacion, compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
