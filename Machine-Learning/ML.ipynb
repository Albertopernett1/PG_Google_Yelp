{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encuentra la ubicacion de spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias para Koalas y definir alias\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import pyspark\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configuramos Spark para poder procesar de forma local archivos de gran tamaño\n",
    "conf = SparkConf().setAppName('appName').setMaster('local') \\\n",
    "    .set(\"spark.network.timeout\", \"600s\") \\\n",
    "    .set(\"spark.driver.memory\", \"12g\") \\\n",
    "    .set(\"spark.executor.memory\", \"10g\") \\\n",
    "    .set(\"spark.executor.cores\", \"4\") \\\n",
    "    .set(\"spark.dynamicAllocation.maxExecutors\", \"2\") \\\n",
    "    .set(\"spark.jars\", r\"C:\\mysql-connector-j-8.1.0\\mysql-connector-j-8.1.0.jar\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-J8U3NTT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>appName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b9c043f220>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found pyspark version \"3.4.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import databricks.koalas as ks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews_Yelp = spark.read.load(r'D:\\Proyecto Integrador Parquet\\Data Warehouse\\Reviews_Yelp.parquet', format='parquet', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Business_Yelp = spark.read.load(r'D:\\Proyecto Integrador Parquet\\Data Warehouse\\ResultadoBUSINESS.parquet', format='parquet', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- word_count: integer (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Reviews_Yelp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Business_Yelp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews_Yelp = Reviews_Yelp.drop(\"review_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Business_Yelp_name = Business_Yelp.select('business_id', 'name', 'state')\n",
    "Business_Yelp_name = Business_Yelp_name.withColumnRenamed(\"name\", \"business_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Crear la matriz de usuarios-negocios\n",
    "user_business_matrix = Reviews_Yelp.groupBy(\"user_id\", \"business_id\") \\\n",
    "    .agg({\"stars\": \"avg\", \"word_count\": \"avg\", \"sentiment_score\": \"avg\", \"useful\": \"avg\", \"funny\": \"avg\", \"cool\": \"avg\"})\n",
    "\n",
    "user_business_matrix = user_business_matrix.join(Business_Yelp_name, \"business_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los valores permitidos para la columna \"state\"\n",
    "allowed_states = [\"CA\", \"TX\", \"NY\", \"FL\", \"IL\"]\n",
    "\n",
    "# Filtrar las filas según los valores permitidos\n",
    "user_business_matrix = user_business_matrix.filter(col(\"state\").isin(allowed_states))\n",
    "user_business_matrix = user_business_matrix.drop('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, lit\n",
    "\n",
    "# Crea una columna constante para usar como criterio de ordenación\n",
    "user_business_matrix = user_business_matrix.withColumn(\"dummy\", lit(1))\n",
    "\n",
    "# Crea una ventana con un orden específico\n",
    "window = Window.orderBy(\"dummy\")\n",
    "\n",
    "# Agrega una columna numerada al DataFrame\n",
    "user_business_matrix = user_business_matrix.withColumn(\"business_id_int\", row_number().over(window))\n",
    "\n",
    "# Elimina la columna dummy si no es necesaria\n",
    "user_business_matrix = user_business_matrix.drop(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_matrix = user_business_matrix.drop('avg(funny)', 'avg(cool)', 'avg(word_count)', 'avg(useful)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+---------------+-----------+\n",
      "|         business_id|             user_id|avg(stars)|avg(sentiment_score)|       business_name|business_id_int|user_id_int|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+---------------+-----------+\n",
      "|S2Ho8yLxhKAa26pBA...|29UB_wrnUIdsxV2Zm...|       3.0|             -0.5267|Creole House Rest...|              1|      51352|\n",
      "|M0r9lUn2gLFYgIwIf...|n2pX5Ae8xCUi2_Wlw...|       5.0|              0.9578|      Baileys' Range|              2|     149150|\n",
      "|vD2jzpPv4iyOLKzIT...|9yxxvX5ySJSylQk3L...|       5.0|              0.4753| Farmhaus Restaurant|              3|     199571|\n",
      "|u7_3L1NBWgxhBM_B-...|JW5W4OZCohTvZlRF1...|       4.0|              0.9868|      Pizzeria Vetri|              4|     163829|\n",
      "|mtGTna-hyFhErb4Zm...|m7l9hVa_dlcvTYjMU...|       2.0|              0.7504|   The Village Diner|              5|      14644|\n",
      "|6PL69ATnM_Y65KmTc...|GX_OXHoG4l0Hykd6H...|       5.0|              0.9324|The Art Supply Store|              6|     119981|\n",
      "|QTeEX_XchMKgS27yX...|hcislsH0jrhvZ5WwJ...|       1.0|             -0.7544|          Wine Works|              7|      81477|\n",
      "|AYSZCdB7oUiKMaOy0...|aRcqznnVb0oL21DJv...|       4.0|              0.9239|     So Good Jewelry|              8|     154293|\n",
      "|YUDcLokFMZOtyWAmV...|yYbpzbfzHvqQojox7...|       2.0|              0.2263|Landry's Seafood ...|              9|      26193|\n",
      "|Eqt-veWZaGVzInCr6...|TPk1CG7OROdgDqBkW...|       5.0|              0.6486|     Sierra Car Care|             10|     180657|\n",
      "|qSSFgdyZ3zZ6qCgLq...|wPQtVVoTrlCYVyJ3w...|       5.0|              0.3987|American Seafood ...|             11|     141843|\n",
      "|3NdRfVpi3-tfk9vdi...|CNjM2009pWONEffyY...|       3.0|             -0.3846|Renaissance New O...|             12|     156453|\n",
      "|pKxOXAuC1i8mnUjxV...|QeNWPBycTDJR6dFXk...|       5.0|              0.9749|               U Gas|             13|      50325|\n",
      "|skN2XhKXlcjf53uIw...|Ytdgo2T5qsrm9_teg...|       4.0|              0.9907|Burger Up - Franklin|             14|      71092|\n",
      "|JvawJ9bSr22xn4R9o...|v4OSDIDxgwqpa4bvH...|       3.0|              0.9657|   Desire Oyster Bar|             15|     136676|\n",
      "|gXdKjP4F16FoUjEar...|Icndzq6HGLf8l-8_k...|       1.0|              0.7852|      Q Auto Brandon|             16|     158588|\n",
      "|UakVMT3xrpbFB2pHd...|IyIsFkVY48JWa01in...|       3.5|             0.89155|        Crown & Bull|             17|      29322|\n",
      "|37BpNvlEAT6WVGsks...|03orKt4OrwqPo4gg4...|       4.0|              0.9747|Batter'd & Fried ...|             18|     183826|\n",
      "|ZlbL-SRrh5B9s7LC9...|9_lcpqJ53tPpo614C...|       4.0|              0.9847|     Hancock Whitney|             19|     135644|\n",
      "|LHSTtnW3YHCeUkRDG...|dJnCcW_dFZ8SeU2Ht...|       3.0|              0.5423|     Fries Rebellion|             20|     130382|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Obtiene los valores únicos de la columna \"user_id\"\n",
    "valores_unicos = user_business_matrix.select(\"user_id\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Crea un diccionario que mapea los valores únicos a números enteros\n",
    "diccionario_mapping = {valor: idx for idx, valor in enumerate(valores_unicos)}\n",
    "\n",
    "# Define una función UDF (User Defined Function) para aplicar el mapeo\n",
    "def mapear_a_numero(valor):\n",
    "    return diccionario_mapping[valor]\n",
    "\n",
    "# Registra la función UDF\n",
    "mapear_a_numero_udf = udf(mapear_a_numero, IntegerType())\n",
    "\n",
    "# Aplica la función UDF para crear la nueva columna \"user_id_int\"\n",
    "user_business_matrix = user_business_matrix.withColumn(\"user_id_int\", mapear_a_numero_udf(user_business_matrix[\"user_id\"]))\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "user_business_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_names = user_business_matrix.select('business_id_int', 'business_name')\n",
    "business_names_pandas = business_names.toPandas()\n",
    "business_names_pandas.to_parquet(r'C:\\Users\\Matías Tejerina\\Desktop\\PG-Google-Yelp\\PG_Google_Yelp\\PG_Google_Yelp\\business_names.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_matrix = user_business_matrix.drop(\"user_id\", \"business_id\", \"business_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+-----------+\n",
      "|avg(stars)|avg(sentiment_score)|business_id_int|user_id_int|\n",
      "+----------+--------------------+---------------+-----------+\n",
      "|       3.0|             -0.5267|              1|      51352|\n",
      "|       5.0|              0.9578|              2|     149150|\n",
      "|       5.0|              0.4753|              3|     199571|\n",
      "|       4.0|              0.9868|              4|     163829|\n",
      "|       2.0|              0.7504|              5|      14644|\n",
      "|       5.0|              0.9324|              6|     119981|\n",
      "|       1.0|             -0.7544|              7|      81477|\n",
      "|       4.0|              0.9239|              8|     154293|\n",
      "|       2.0|              0.2263|              9|      26193|\n",
      "|       5.0|              0.6486|             10|     180657|\n",
      "|       5.0|              0.3987|             11|     141843|\n",
      "|       3.0|             -0.3846|             12|     156453|\n",
      "|       5.0|              0.9749|             13|      50325|\n",
      "|       4.0|              0.9907|             14|      71092|\n",
      "|       3.0|              0.9657|             15|     136676|\n",
      "|       1.0|              0.7852|             16|     158588|\n",
      "|       3.5|             0.89155|             17|      29322|\n",
      "|       4.0|              0.9747|             18|     183826|\n",
      "|       4.0|              0.9847|             19|     135644|\n",
      "|       3.0|              0.5423|             20|     130382|\n",
      "+----------+--------------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_business_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+-----------+------+\n",
      "|avg(stars)|avg(sentiment_score)|business_id_int|user_id_int|rating|\n",
      "+----------+--------------------+---------------+-----------+------+\n",
      "|       3.0|             -0.5267|              1|      51352|0.4183|\n",
      "|       5.0|              0.9578|              2|     149150|0.9894|\n",
      "|       5.0|              0.4753|              3|     199571|0.8688|\n",
      "|       4.0|              0.9868|              4|     163829|0.8967|\n",
      "|       2.0|              0.7504|              5|      14644|0.6376|\n",
      "|       5.0|              0.9324|              6|     119981|0.9831|\n",
      "|       1.0|             -0.7544|              7|      81477|0.1614|\n",
      "|       4.0|              0.9239|              8|     154293| 0.881|\n",
      "|       2.0|              0.2263|              9|      26193|0.5066|\n",
      "|       5.0|              0.6486|             10|     180657|0.9122|\n",
      "|       5.0|              0.3987|             11|     141843|0.8497|\n",
      "|       3.0|             -0.3846|             12|     156453|0.4539|\n",
      "|       5.0|              0.9749|             13|      50325|0.9937|\n",
      "|       4.0|              0.9907|             14|      71092|0.8977|\n",
      "|       3.0|              0.9657|             15|     136676|0.7914|\n",
      "|       1.0|              0.7852|             16|     158588|0.5463|\n",
      "|       3.5|             0.89155|             17|      29322|0.8229|\n",
      "|       4.0|              0.9747|             18|     183826|0.8937|\n",
      "|       4.0|              0.9847|             19|     135644|0.8962|\n",
      "|       3.0|              0.5423|             20|     130382|0.6856|\n",
      "+----------+--------------------+---------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, round\n",
    "def calcular_calificacion_combinada(row):\n",
    "    peso = 0.5  # Peso igual para ambas columnas\n",
    "    stars = row[\"avg(stars)\"] / 5  # Normaliza \"stars\" al rango de 0 a 1\n",
    "    sentiment_score = (row[\"avg(sentiment_score)\"] + 1) / 2  # Normaliza \"sentiment_score\" al rango de 0 a 1\n",
    "    calificacion_combinada = (stars * peso) + (sentiment_score * peso)\n",
    "    return calificacion_combinada\n",
    "\n",
    "# Aplicar la función a todas las columnas y agregar la nueva columna \"rating\"\n",
    "user_business_matrix = user_business_matrix.withColumn(\"rating\", calcular_calificacion_combinada(user_business_matrix))\n",
    "user_business_matrix = user_business_matrix.withColumn(\"rating\", round(user_business_matrix[\"rating\"], 4))\n",
    "\n",
    "user_business_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_matrix = user_business_matrix.drop('avg(stars)', 'avg(sentiment_score)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1494418"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_business_matrix.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id_int: integer (nullable = false)\n",
      " |-- user_id_int: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_business_matrix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "user_business_matrix = user_business_matrix.filter(col(\"user_id_int\") <= 6745760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business_matrix = user_business_matrix.filter(col(\"business_id_int\") <= 6745760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo ALS (Alternating Least Squares)\n",
    "als_final = ALS(maxIter=10, regParam=0.01, userCol=\"user_id_int\", itemCol=\"business_id_int\", ratingCol=\"rating\")\n",
    "\n",
    "# Entrenar el modelo ALS\n",
    "model_final = als_final.fit(user_business_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|user_id_int|     recommendations|\n",
      "+-----------+--------------------+\n",
      "|        456|[{659400, 0.99148...|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el ID del usuario que deseas utilizar\n",
    "user_id = 456\n",
    "\n",
    "# Filtrar el DataFrame para obtener las recomendaciones para ese usuario\n",
    "user_df = user_business_matrix.filter(user_business_matrix[\"user_id_int\"] == user_id).select(\"user_id_int\")\n",
    "user_recs = model_final.recommendForUserSubset(user_df, 10)  # Obtener 10 recomendaciones\n",
    "\n",
    "# Mostrar las recomendaciones\n",
    "user_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = user_recs.select(\"recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|recommendations                                                                                                                                                                                                           |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{659400, 0.9914801}, {966963, 0.9632091}, {255107, 0.9625022}, {1366884, 0.95846516}, {175600, 0.95614815}, {1473841, 0.94096786}, {480270, 0.93522567}, {449399, 0.9286774}, {319467, 0.92497885}, {1177494, 0.9206134}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zlatno Zito', 'ZaZa Nails & Spa', 'Great Basin Data Recovery', 'Oasis Nails & Spa', 'Dairy Queen Grill & Chill', 'The Cheesecake Factory', \"Positano's\", \"McGuire's Barber Shop\", 'Café Amelie', \"Vincent's Italian Cuisine\"]\n"
     ]
    }
   ],
   "source": [
    "# Recopila los datos en una lista de filas\n",
    "rows = a.collect()\n",
    "\n",
    "# Procesa la lista de filas para crear el diccionario de recomendaciones\n",
    "recommendations_dict = {}\n",
    "for row in rows:\n",
    "    recommendations_dict.update(dict(row.recommendations))\n",
    "\n",
    "# Recopila los keys (business_id_int) de las recomendaciones\n",
    "keys = recommendations_dict.keys()\n",
    "\n",
    "# Filtra el DataFrame business_names_pandas para obtener los nombres correspondientes a los keys\n",
    "top10_recs = business_names_pandas[business_names_pandas['business_id_int'].isin(keys)]['business_name'].tolist()\n",
    "\n",
    "# Tomar los primeros 10 elementos de la lista (top 10 recomendaciones)\n",
    "names_list = top10_recs[:10]\n",
    "\n",
    "# Muestra la lista resultante\n",
    "print(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado en un archivo\n",
    "model_final.save(r\"C:\\Users\\Matías Tejerina\\Desktop\\PG-Google-Yelp\\PG_Google_Yelp\\PG_Google_Yelp\\modelo_als\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
